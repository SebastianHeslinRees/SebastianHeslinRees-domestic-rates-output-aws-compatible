{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter data to 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyreadr\n",
    "import pyarrow \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     gss_out     sex  age     gss_in      rate  year\n",
      "0  E06000001  female  0.0  E06000002  0.000000  2022\n",
      "1  E06000001  female  0.0  E06000003  0.000000  2022\n",
      "2  E06000001  female  0.0  E06000004  0.001884  2022\n",
      "3  E06000001  female  0.0  E06000005  0.000000  2022\n",
      "4  E06000001  female  0.0  E06000006  0.000000  2022\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the S3 path\n",
    "s3_path = \"s3://dpa-population-projection-data/population_mid_year_estimates/outputs/parquet_backseries_rates/year=2022/part-0.parquet\"\n",
    "\n",
    "# Read the Parquet file directly from S3 (requires s3fs)\n",
    "df_parquet = pd.read_parquet(s3_path, engine='pyarrow')\n",
    "print(df_parquet.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (14903802, 6)\n",
      "Length: 14903802\n",
      "Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14903802 entries, 0 to 14903801\n",
      "Data columns (total 6 columns):\n",
      " #   Column   Dtype   \n",
      "---  ------   -----   \n",
      " 0   gss_out  object  \n",
      " 1   sex      object  \n",
      " 2   age      float64 \n",
      " 3   gss_in   object  \n",
      " 4   rate     float64 \n",
      " 5   year     category\n",
      "dtypes: category(1), float64(2), object(3)\n",
      "memory usage: 582.7+ MB\n",
      "None\n",
      "Description:\n",
      "          gss_out       sex           age     gss_in          rate        year\n",
      "count    14903802  14903802  1.490380e+07   14903802  1.490380e+07  14903802.0\n",
      "unique        320         2           NaN        320           NaN         1.0\n",
      "top     E08000025    female           NaN  S92000003           NaN      2022.0\n",
      "freq        57967   7491566           NaN      57868           NaN  14903802.0\n",
      "mean          NaN       NaN  4.500329e+01        NaN  2.239762e-04         NaN\n",
      "std           NaN       NaN  2.626600e+01        NaN  1.447617e-03         NaN\n",
      "min           NaN       NaN  0.000000e+00        NaN  0.000000e+00         NaN\n",
      "25%           NaN       NaN  2.200000e+01        NaN  0.000000e+00         NaN\n",
      "50%           NaN       NaN  4.500000e+01        NaN  0.000000e+00         NaN\n",
      "75%           NaN       NaN  6.800000e+01        NaN  0.000000e+00         NaN\n",
      "max           NaN       NaN  9.000000e+01        NaN  8.840000e-01         NaN\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape:\", df_parquet.shape)\n",
    "print(\"Length:\", len(df_parquet))\n",
    "print(\"Info:\")\n",
    "print(df_parquet.info())\n",
    "print(\"Description:\")\n",
    "print(df_parquet.describe(include='all'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (14613489, 6)\n",
      "Length: 14613489\n",
      "Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14613489 entries, 0 to 14613488\n",
      "Data columns (total 6 columns):\n",
      " #   Column   Dtype   \n",
      "---  ------   -----   \n",
      " 0   gss_out  object  \n",
      " 1   sex      object  \n",
      " 2   age      float64 \n",
      " 3   gss_in   object  \n",
      " 4   rate     float64 \n",
      " 5   year     category\n",
      "dtypes: category(1), float64(2), object(3)\n",
      "memory usage: 571.4+ MB\n",
      "None\n",
      "Description:\n",
      "          gss_out       sex           age     gss_in          rate        year\n",
      "count    14613489  14613489  1.461349e+07   14613489  1.461349e+07  14613489.0\n",
      "unique        320         2           NaN        320           NaN         1.0\n",
      "top     E08000025      male           NaN  S92000003           NaN      2012.0\n",
      "freq        57694   7314479           NaN      57868           NaN  14613489.0\n",
      "mean          NaN       NaN  4.500342e+01        NaN  1.939199e-04         NaN\n",
      "std           NaN       NaN  2.626592e+01        NaN  1.344533e-03         NaN\n",
      "min           NaN       NaN  0.000000e+00        NaN  0.000000e+00         NaN\n",
      "25%           NaN       NaN  2.200000e+01        NaN  0.000000e+00         NaN\n",
      "50%           NaN       NaN  4.500000e+01        NaN  0.000000e+00         NaN\n",
      "75%           NaN       NaN  6.800000e+01        NaN  0.000000e+00         NaN\n",
      "max           NaN       NaN  9.000000e+01        NaN  1.000000e+00         NaN\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape:\", df_parquet_2012.shape)\n",
    "print(\"Length:\", len(df_parquet_2012))\n",
    "print(\"Info:\")\n",
    "print(df_parquet_2012.info())\n",
    "print(\"Description:\")\n",
    "print(df_parquet_2012.describe(include='all'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     gss_out     sex  age     gss_in      rate  year\n",
      "0  E06000001  female  0.0  E06000002  0.000751  2012\n",
      "1  E06000001  female  0.0  E06000003  0.000330  2012\n",
      "2  E06000001  female  0.0  E06000004  0.000547  2012\n",
      "3  E06000001  female  0.0  E06000005  0.000000  2012\n",
      "4  E06000001  female  0.0  E06000007  0.000000  2012\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the S3 path\n",
    "s3_path = \"s3://dpa-population-projection-data/population_mid_year_estimates/outputs/parquet_backseries_rates/year=2012/part-0.parquet\"\n",
    "\n",
    "# Read the Parquet file directly from S3 (requires s3fs)\n",
    "df_parquet_2012 = pd.read_parquet(s3_path, engine='pyarrow')\n",
    "print(df_parquet_2012.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      None\n",
      "0  dom_rates_avg_2013_2022\n"
     ]
    }
   ],
   "source": [
    "import pyreadr\n",
    "\n",
    "# Define the S3 bucket and key for the .rds file\n",
    "s3_bucket = \"dpa-population-projection-data\"\n",
    "s3_key = \"population_mid_year_estimates/outputs/averaged_rates/2022_dom_10yr_avg.rds\"\n",
    "\n",
    "import tempfile\n",
    "\n",
    "# Read the file from S3\n",
    "response = s3.get_object(Bucket=s3_bucket, Key=s3_key)\n",
    "file_content = response['Body'].read()\n",
    "\n",
    "# Save to a temporary file and read with pyreadr\n",
    "with tempfile.NamedTemporaryFile(suffix=\".rds\") as tmp:\n",
    "\ttmp.write(file_content)\n",
    "\ttmp.flush()\n",
    "\tresult = pyreadr.read_r(tmp.name)\n",
    "\n",
    "# Extract the DataFrame\n",
    "df_rds = list(result.values())[0]\n",
    "print(df_rds.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    gss_code    gss_name     sex    year  age   component  value\n",
      "0  E06000001  Hartlepool  female  2001.0  0.0  population  519.0\n",
      "1  E06000001  Hartlepool  female  2001.0  1.0  population  550.0\n",
      "2  E06000001  Hartlepool  female  2001.0  2.0  population  548.0\n",
      "3  E06000001  Hartlepool  female  2001.0  3.0  population  523.0\n",
      "4  E06000001  Hartlepool  female  2001.0  4.0  population  589.0\n"
     ]
    }
   ],
   "source": [
    "import pyreadr\n",
    "\n",
    "# Define the file path\n",
    "file_path = \"/Users/user1/Documents/get_rate_backseries/input_data/full_modelled_estimates_series_EW(2023_geog).rds\"\n",
    "\n",
    "# Read the .rds file\n",
    "result = pyreadr.read_r(file_path)\n",
    "\n",
    "# Extract the DataFrame (assuming there's only one dataset inside the file)\n",
    "df = list(result.values())[0]\n",
    "\n",
    "# Display the first few rows\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter df by component == population\n",
    "df_population = df[df['component'] == 'population']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyreadr.write_rds('/Users/user1/Documents/get_rate_backseries/input_data/population_gla_2022.rds', df_population)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'env (Python -1.-1.-1)' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "# Define the file path\n",
    "file_path = \"/Users/user1/Documents/get_rate_backseries/input_data/full_modelled_estimates_series_EW(2023_geog).rds\"\n",
    "\n",
    "\n",
    "# Read the .rds file\n",
    "result = pyreadr.read_r(file_path)\n",
    "\n",
    "# Extract the DataFrame (assuming there's only one dataset inside the file)\n",
    "df = list(result.values())[0]\n",
    "\n",
    "# Display the first few rows\n",
    "print(df.head())\"\n",
    "\n",
    "# Read the .rds file\n",
    "result = pyreadr.read_r(file_path)\n",
    "\n",
    "# Extract the DataFrame (assuming there's only one dataset inside the file)\n",
    "df = list(result.values())[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          gss_code    gss_name     sex    year  age component  value\n",
      "5266725  E06000001  Hartlepool  female  2021.0  0.0    births  436.0\n",
      "5266735  E06000001  Hartlepool  female  2021.0  1.0    births    0.0\n",
      "5266745  E06000001  Hartlepool  female  2021.0  2.0    births    0.0\n",
      "5266755  E06000001  Hartlepool  female  2021.0  3.0    births    0.0\n",
      "5266765  E06000001  Hartlepool  female  2021.0  4.0    births    0.0\n"
     ]
    }
   ],
   "source": [
    "#filter the data year 2021\n",
    "df_2021 = df[df['year'] == 2021]\n",
    "print(df_2021.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter component = births\n",
    "df_births_2021 = df_2021[df_2021['component'] == 'births']\n",
    "#filter component = population\n",
    "df_population_2021 = df_2021[df_2021['component'] == 'population']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths\n",
    "births_rds_path = \"/Users/user1/Documents/get_rate_backseries/input_data/2021/births_2021.rds\"\n",
    "population_rds_path = \"/Users/user1/Documents/get_rate_backseries/input_data/2021/population_2021.rds\"\n",
    "\n",
    "# Save DataFrames to .rds format\n",
    "pyreadr.write_rds(births_rds_path, df_births_2021)\n",
    "pyreadr.write_rds(population_rds_path, df_population_2021)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/envs/env/lib/python3.12/site-packages/pyreadr/librdata.pyx:264\u001b[0m, in \u001b[0;36mpyreadr.librdata.Parser._Parser__handle_text_value\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/env/lib/python3.12/site-packages/pyreadr/_pyreadr_parser.py:387\u001b[0m, in \u001b[0;36mPyreadrParser.handle_text_value\u001b[0;34m(self, name, index)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_current_table:\n\u001b[1;32m    384\u001b[0m         \u001b[38;5;66;03m#self.current_table.row_names[index] = name\u001b[39;00m\n\u001b[1;32m    385\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_table\u001b[38;5;241m.\u001b[39mrow_names\u001b[38;5;241m.\u001b[39mappend(name)\n\u001b[0;32m--> 387\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mhandle_text_value\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, index):\n\u001b[1;32m    388\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;124;03m    For character vectors this will be called once per row and will retrieve the string value for that row.\u001b[39;00m\n\u001b[1;32m    390\u001b[0m \u001b[38;5;124;03m    :param name: str: string value for the row\u001b[39;00m\n\u001b[1;32m    391\u001b[0m \u001b[38;5;124;03m    :param index: int: index of the row\u001b[39;00m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;124;03m    :return:\u001b[39;00m\n\u001b[1;32m    393\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    394\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_current_table:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'pyreadr.librdata._handle_text_value'\n",
      "Traceback (most recent call last):\n",
      "  File \"pyreadr/librdata.pyx\", line 264, in pyreadr.librdata.Parser._Parser__handle_text_value\n",
      "  File \"/opt/anaconda3/envs/env/lib/python3.12/site-packages/pyreadr/_pyreadr_parser.py\", line 387, in handle_text_value\n",
      "    def handle_text_value(self, name, index):\n",
      "\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/user1/Documents/get_rate_backseries/input_data/2021/origin_destination_2002_2022_(2023_geog).rds\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Read the .rds file\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mpyreadr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_r\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Extract the DataFrame (assuming there's only one dataset inside the file)\u001b[39;00m\n\u001b[1;32m     11\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(result\u001b[38;5;241m.\u001b[39mvalues())[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/env/lib/python3.12/site-packages/pyreadr/pyreadr.py:70\u001b[0m, in \u001b[0;36mread_r\u001b[0;34m(path, use_objects, timezone)\u001b[0m\n\u001b[1;32m     68\u001b[0m result \u001b[38;5;241m=\u001b[39m OrderedDict()\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m table_index, table \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(parser\u001b[38;5;241m.\u001b[39mtable_data):\n\u001b[0;32m---> 70\u001b[0m     result[table\u001b[38;5;241m.\u001b[39mname] \u001b[38;5;241m=\u001b[39m \u001b[43mtable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_pandas_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/anaconda3/envs/env/lib/python3.12/site-packages/pyreadr/_pyreadr_parser.py:55\u001b[0m, in \u001b[0;36mTable.convert_to_pandas_dataframe\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_arraylike_todf()\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 55\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dflike_todf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf\n",
      "File \u001b[0;32m/opt/anaconda3/envs/env/lib/python3.12/site-packages/pyreadr/_pyreadr_parser.py:182\u001b[0m, in \u001b[0;36mTable._dflike_todf\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;124;03mThis one is for objects that do not have the dim attribute set: dataframes\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;124;03mand atomic vectors. (but vectors can have the dim attribute in that case\u001b[39;00m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;124;03mthey go to the other method)\u001b[39;00m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_consolidate_names()\n\u001b[0;32m--> 182\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_todf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_covert_data()\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_value_labels()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/env/lib/python3.12/site-packages/pyreadr/_pyreadr_parser.py:213\u001b[0m, in \u001b[0;36mTable._todf\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    211\u001b[0m     colname \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinal_names[indx]\n\u001b[1;32m    212\u001b[0m     data[colname] \u001b[38;5;241m=\u001b[39m column\n\u001b[0;32m--> 213\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf \u001b[38;5;241m=\u001b[39m df\n",
      "File \u001b[0;32m/opt/anaconda3/envs/env/lib/python3.12/site-packages/pandas/core/frame.py:1917\u001b[0m, in \u001b[0;36mDataFrame.from_dict\u001b[0;34m(cls, data, orient, dtype, columns)\u001b[0m\n\u001b[1;32m   1911\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1912\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtight\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for orient parameter. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1913\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00morient\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m instead\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1914\u001b[0m     )\n\u001b[1;32m   1916\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m orient \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtight\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1918\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1919\u001b[0m     realdata \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/env/lib/python3.12/site-packages/pandas/core/frame.py:778\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    772\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[1;32m    773\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[1;32m    774\u001b[0m     )\n\u001b[1;32m    776\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    777\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[0;32m--> 778\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    779\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[1;32m    780\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[0;32m/opt/anaconda3/envs/env/lib/python3.12/site-packages/pandas/core/internals/construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[1;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[0;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/env/lib/python3.12/site-packages/pandas/core/internals/construction.py:114\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 114\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    116\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/env/lib/python3.12/site-packages/pandas/core/internals/construction.py:677\u001b[0m, in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    675\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[1;32m    676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 677\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    679\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[1;32m    680\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    681\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    682\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "import pyreadr\n",
    "\n",
    "# Define the file path\n",
    "file_path = \"/Users/user1/Documents/get_rate_backseries/input_data/2021/origin_destination_2002_2022_(2023_geog).rds\"\n",
    "\n",
    "# Read the .rds file\n",
    "result = pyreadr.read_r(file_path)\n",
    "\n",
    "\n",
    "# Extract the DataFrame (assuming there's only one dataset inside the file)\n",
    "df = list(result.values())[0]\n",
    "\n",
    "# Display the first few rows\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index              132\n",
      "gss_out    10642543540\n",
      "gss_in     10642543540\n",
      "year        1467937040\n",
      "sex         9909096066\n",
      "age         1467937040\n",
      "value       1467937040\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#check memeory usage of the dataframe\n",
    "print(df.memory_usage(deep=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 183492130 entries, 0 to 183492129\n",
      "Data columns (total 6 columns):\n",
      " #   Column   Dtype  \n",
      "---  ------   -----  \n",
      " 0   gss_out  object \n",
      " 1   gss_in   object \n",
      " 2   year     float64\n",
      " 3   sex      object \n",
      " 4   age      float64\n",
      " 5   value    float64\n",
      "dtypes: float64(3), object(3)\n",
      "memory usage: 33.2 GB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.info(memory_usage='deep'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['gss_out', 'gss_in', 'sex']:  \n",
    "    df[col] = df[col].astype('category')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['year'] = pd.to_numeric(df['year'], downcast='integer')\n",
    "df['age'] = pd.to_numeric(df['age'], downcast='integer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['value'] = pd.to_numeric(df['value'], downcast='float')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index            132\n",
      "gss_out    367011116\n",
      "gss_in     367011116\n",
      "year       366984260\n",
      "sex        183492346\n",
      "age        183492130\n",
      "value      733968520\n",
      "dtype: int64\n",
      "gss_out    category\n",
      "gss_in     category\n",
      "year          int16\n",
      "sex        category\n",
      "age            int8\n",
      "value       float32\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.memory_usage(deep=True))\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save as csv\n",
    "df.to_csv('/Users/user1/Documents/get_rate_backseries/input_data/2021/origin_destination_2002_2022_(2023_geog)_reduced_mem.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in csv\n",
    "df = pd.read_csv('/Users/user1/Documents/get_rate_backseries/input_data/2021/origin_destination_2002_2022_(2023_geog)_reduced_mem.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#folter year 2021\n",
    "df_2021 = df[df['year'] == 2021]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save as csv\n",
    "df_2021.to_csv('/Users/user1/Documents/get_rate_backseries/input_data/2021/origin_destination_2002_2022_(2023_geog)_reduced_mem_2021.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    gss_code    year     sex  age   popn\n",
      "0  E06000001  2001.0  female  0.0  519.0\n",
      "1  E06000001  2002.0  female  0.0  499.0\n",
      "2  E06000001  2003.0  female  0.0  513.0\n",
      "3  E06000001  2004.0  female  0.0  517.0\n",
      "4  E06000001  2005.0  female  0.0  551.0\n"
     ]
    }
   ],
   "source": [
    "#population data\n",
    "import pyreadr\n",
    "\n",
    "# Define the file path\n",
    "file_path = \"/Users/user1/Documents/get_rate_backseries/input_data/population_gla_2022.rds\"\n",
    "\n",
    "# Read the .rds file\n",
    "result = pyreadr.read_r(file_path)\n",
    "\n",
    "\n",
    "# Extract the DataFrame (assuming there's only one dataset inside the file)\n",
    "df = list(result.values())[0]\n",
    "\n",
    "# Display the first few rows\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          gss_code    year     sex   age   popn\n",
      "1265082  E06000001  2011.0  female   0.0  555.0\n",
      "1265083  E06000001  2011.0  female   1.0  584.0\n",
      "1265084  E06000001  2011.0  female   2.0  561.0\n",
      "1265085  E06000001  2011.0  female   3.0  565.0\n",
      "1265086  E06000001  2011.0  female   4.0  546.0\n",
      "...            ...     ...     ...   ...    ...\n",
      "1901711  W06000024  2021.0    male  84.0  106.0\n",
      "1901712  W06000024  2021.0    male  85.0  100.0\n",
      "1901715  W06000024  2021.0    male  88.0   50.0\n",
      "1901716  W06000024  2021.0    male  89.0   50.0\n",
      "1901717  W06000024  2021.0    male  90.0  122.0\n",
      "\n",
      "[124215 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "#show duplicate rows\n",
    "duplicateRowsDF = df[df.duplicated()]\n",
    "print(duplicateRowsDF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find duplicate rows and show both original and duplicate rows\n",
    "df_duplicates = df[df.duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          gss_code    year     sex   age   popn\n",
      "10       E06000001  2011.0  female   0.0  555.0\n",
      "31       E06000001  2011.0  female   1.0  584.0\n",
      "32       E06000001  2012.0  female   1.0  557.0\n",
      "39       E06000001  2019.0  female   1.0  462.0\n",
      "41       E06000001  2021.0  female   1.0  477.0\n",
      "...            ...     ...     ...   ...    ...\n",
      "1901711  W06000024  2021.0    male  84.0  106.0\n",
      "1901712  W06000024  2021.0    male  85.0  100.0\n",
      "1901715  W06000024  2021.0    male  88.0   50.0\n",
      "1901716  W06000024  2021.0    male  89.0   50.0\n",
      "1901717  W06000024  2021.0    male  90.0  122.0\n",
      "\n",
      "[248430 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          gss_code    year     sex  age   popn\n",
      "10       E06000001  2011.0  female  0.0  555.0\n",
      "1265082  E06000001  2011.0  female  0.0  555.0\n"
     ]
    }
   ],
   "source": [
    "row = df.query(\"gss_code == 'E06000001' and year == 2011 and sex == 'female' and age == 0\")\n",
    "print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      gss_code    year     sex  age   popn\n",
      "19   E06000001  2020.0  female  0.0  457.0\n",
      "40   E06000001  2020.0  female  1.0  502.0\n",
      "61   E06000001  2020.0  female  2.0  462.0\n",
      "82   E06000001  2020.0  female  3.0  522.0\n",
      "103  E06000001  2020.0  female  4.0  524.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df \n",
    "#filter year 2020\n",
    "df_2020 = df[df['year'] == 2020]\n",
    "print(df_2020.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save as rds\n",
    "pyreadr.write_rds('/Users/user1/Documents/get_rate_backseries/input_data/population_gla_2022_filtered.rds', df_2020)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pyreadr\n",
    "import tempfile\n",
    "\n",
    "# Define the AWS credentials and region\n",
    "AWS_ACCESS_KEY_ID = \"AKIAZI2LHNUCPTKR6GPC\"\n",
    "AWS_SECRET_ACCESS_KEY = \"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\"\n",
    "AWS_DEFAULT_REGION = \"eu-west-2\"\n",
    "\n",
    "# Define the S3 bucket and key\n",
    "s3_bucket = \"dpa-population-projection-data\"\n",
    "s3_key = \"population_mid_year_estimates/2022/origin_destination_2002_2022_(2023_geog).rds\"\n",
    "\n",
    "# Initialize S3 client\n",
    "s3 = boto3.client(\n",
    "    's3',\n",
    "    aws_access_key_id=AWS_ACCESS_KEY_ID,\n",
    "    aws_secret_access_key=AWS_SECRET_ACCESS_KEY,\n",
    "    region_name=AWS_DEFAULT_REGION\n",
    ")\n",
    "\n",
    "# Read the file from S3\n",
    "response = s3.get_object(Bucket=s3_bucket, Key=s3_key)\n",
    "file_content = response['Body'].read()\n",
    "\n",
    "# Save to a temporary file\n",
    "with tempfile.NamedTemporaryFile(suffix=\".rds\") as tmp:\n",
    "    tmp.write(file_content)\n",
    "    tmp.flush()  # Make sure data is written\n",
    "\n",
    "    # Now read it with pyreadr\n",
    "    result = pyreadr.read_r(tmp.name)\n",
    "\n",
    "# Extract the DataFrame\n",
    "df = list(result.values())[0]\n",
    "\n",
    "# Display the first few rows\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
